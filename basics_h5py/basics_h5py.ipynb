{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "573ffeea",
   "metadata": {},
   "source": [
    "#  `h5py` Notes\n",
    "- Resource: https://docs.h5py.org/en/stable/index.html\n",
    "- Resource: Course-571740000 `Data Processing for Engineers and Scientists` \n",
    "- Install it first by typing `conda install h5py` OR `pip install h5py` on terminal\n",
    "- --Wen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "b5917d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1f92bb",
   "metadata": {},
   "source": [
    "## Creating/opening hdf5 files\n",
    "`hdf5` files are created/opened with the same command: `<file_object> = h5py.File(<path_to_file>, <permission_mode>, <...>)`.\n",
    "- The set permission mode determines how `h5py` accesses the file. Valid modes are:\n",
    "    - `r`: read only (file must exist already) $\\qquad\\rightarrow $ this is the default setting\n",
    "    - `r+`: read/write (file must exist already)\n",
    "    - `w`: create file (overwrite if file exists)\n",
    "    - `w-` / `x`: create file (fails if file exists)\n",
    "    - `a`: read/write if the file exists already, otherwise creates the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "61844fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path for the file in the 'data' folder\n",
    "filename = os.path.join('data', 'my_first_file.h5')\n",
    "\n",
    "# Create an HDF5 file with write permission mode ('w' for write)\n",
    "h5file = h5py.File(filename, 'w')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6948a67e",
   "metadata": {},
   "source": [
    "## Creating a first data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "6fb0160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the created file allocate storage for an array of shape (128,3) where all elements are integers.\n",
    "# Name it `first_dataset`\n",
    "my_data = h5file.create_dataset('first_dataset', shape=(128, 3), dtype='i')\n",
    "    \n",
    "#Fill the dataset `my_data` with all ones\n",
    "my_data[:] = np.ones((128, 3), dtype='i')\n",
    "    \n",
    "#Create a second dataset named second_dataset in the hdf5 file \n",
    "#which is an array of shape (20,20) containing only zeros \n",
    "#using the keyword data.\n",
    "my_data_2 = h5file.create_dataset( 'second_dataset', data=np.zeros((20,20)),dtype='i' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd4daa",
   "metadata": {},
   "source": [
    "## Bringing in some structure using groups and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bea41af4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Creating a group\n",
    "#Add a new group named first_group to the open hdf5-file.\n",
    "first_group = h5file.create_group('first_group')\n",
    "\n",
    "#Adding metadata\n",
    "metadata_dict = {\n",
    "    'created_by': 'Your Name',\n",
    "    'creation_date': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'h5py_version': h5py.__version__\n",
    "}\n",
    "first_group.attrs.update(metadata_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89999698",
   "metadata": {},
   "source": [
    "### Writing data directly to groups\n",
    "- There are two main approaches to creating a dataset inside a specific folder:\n",
    "    - `<group_reference>.create_dataset(..)`\n",
    "        - `create_dataset()` is called on the reference of the group.\n",
    "        - This makes sense if you already have a reference around.\n",
    "    - `h5file[ <group_name_in_the_file> ].create_dataset(..)`\n",
    "        - `h5file[ <group_name_in_the_file> ]` gets the reference to create the dataset in.\n",
    "        - Here, the group is accessed by name in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "78c76965",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wen\n"
     ]
    }
   ],
   "source": [
    "# Generate a random array\n",
    "random_array = np.random.rand(219)\n",
    "\n",
    "# Create a dataset named 'third_dataset' in 'first_group' containing 'random_array'\n",
    "my_data_3 = first_group.create_dataset('third_dataset', data=random_array)\n",
    "\n",
    "# Define and add metadata\n",
    "metadata = {\n",
    "    'created_by': 'Wen',\n",
    "    'creation_date': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'h5py_version': h5py.__version__\n",
    "}\n",
    "my_data_3.attrs.update(metadata)\n",
    "\n",
    "# Print the value of the attribute 'created_by'\n",
    "print(my_data_3.attrs['created_by'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570fec11",
   "metadata": {},
   "source": [
    "## Closing `hdf5` files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f51c5c83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wen\n"
     ]
    }
   ],
   "source": [
    "h5file.close()\n",
    "\n",
    "# All references to the file are lost\n",
    "# Using a context manager in form of a `with`-statement\n",
    "with h5py.File(\"data/my_first_file.h5\", \"a\") as h5file:\n",
    "    # Access 'first_group' and the dataset 'third_dataset'\n",
    "    my_group = h5file['first_group']\n",
    "    my_data_3 = my_group['third_dataset']\n",
    "    \n",
    "    # Print the value of the attribute 'created_by'\n",
    "    print(my_data_3.attrs['created_by'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4180a806",
   "metadata": {},
   "source": [
    "### if I don't close files..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a897e270",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    h5file = h5py.File('./data/my_first_file.h5', 'r')\n",
    "    return h5file['first_dataset']      # Read dataset that you have created (we will come back to 'reading data' later)\n",
    "\n",
    "some_data = get_dataset()\n",
    "\n",
    "# Although h5file is out of scope the file remains open due to the reference 'some_data'\n",
    "\n",
    "# Delete the reference\n",
    "del some_data\n",
    "\n",
    "# File will be closed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3201b371",
   "metadata": {},
   "source": [
    "### Display content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2ba0787f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the HDF5 file:\n",
      "<KeysViewHDF5 ['first_dataset', 'first_group', 'second_dataset']>\n",
      "\n",
      "Keys in 'first_group':\n",
      "<KeysViewHDF5 ['third_dataset']>\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"data/my_first_file.h5\", \"a\") as h5file:\n",
    "    # Display keys at the top level of the HDF5 file\n",
    "    print(\"Keys in the HDF5 file:\")\n",
    "    print(h5file.keys())\n",
    "\n",
    "    # Access 'first_group'\n",
    "    my_group = h5file['first_group']\n",
    "\n",
    "    # Display keys within 'first_group'\n",
    "    print(\"\\nKeys in 'first_group':\")\n",
    "    print(my_group.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6dac1466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first_dataset\n",
      "first_group\n",
      "first_group/third_dataset\n",
      "second_dataset\n"
     ]
    }
   ],
   "source": [
    "def printPath(path):\n",
    "    print(path)\n",
    "\n",
    "with h5py.File(\"data/my_first_file.h5\", \"a\") as h5file:\n",
    "    h5file.visit(printPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47b06a",
   "metadata": {},
   "source": [
    "### Check whether a certain path exists in an hdf5-file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "451734b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does 'first_dataset' exist?\t\t ----> True\n",
      "Does 'first_group/third_dataset' exist?\t ----> True\n",
      "Does 'wrong_path/weird_dataset' exist?\t ----> False\n"
     ]
    }
   ],
   "source": [
    "with h5py.File('data/my_first_file.h5', 'r') as h5file:\n",
    "    condition_1 = \"first_dataset\" in h5file\n",
    "    print(\"Does 'first_dataset' exist?\\t\\t ----> {}\".format(condition_1))\n",
    "\n",
    "    condition_2 = \"first_group/third_dataset\" in h5file\n",
    "    print(\"Does 'first_group/third_dataset' exist?\\t ----> {}\".format(condition_2))\n",
    "\n",
    "    condition_3 = \"wrong_path/weird_dataset\" in h5file\n",
    "    print(\"Does 'wrong_path/weird_dataset' exist?\\t ----> {}\".format(condition_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f32de",
   "metadata": {},
   "source": [
    "## Accessing `hdf5`-files\n",
    "- To load data from a file as a reference we use `<variable_reference> = <file_object>['<path']`.\n",
    "- To load data into memory simply use slicing, i.e. `<variable_in_memory> = <file_object>['<path'][:]` would load the entire dataset into memory. Of course this also works for parts of the dataset that are sliced. To load a dataset consisting of a scalar to memory use `<file_object>['<path'][()]`.\n",
    "- Read/write operations are generally slower when accessing data directly from the hard drive. However, the loss of computational speed is, in most cases, negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "69938c9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys in the HDF5 file:\n",
      "<KeysViewHDF5 ['image_data']>\n",
      "\n",
      "File structure using visit:\n",
      "image_data\n",
      "image_data/dset_0\n",
      "image_data/dset_1\n",
      "image_data/dset_10\n",
      "image_data/dset_11\n",
      "image_data/dset_2\n",
      "image_data/dset_3\n",
      "image_data/dset_4\n",
      "image_data/dset_5\n",
      "image_data/dset_6\n",
      "image_data/dset_7\n",
      "image_data/dset_8\n",
      "image_data/dset_9\n"
     ]
    }
   ],
   "source": [
    "# Open the provided HDF5 file in read-only mode\n",
    "with h5py.File(\"data/images.h5\", \"r\") as h5file:\n",
    "    # Display keys at the top level of the HDF5 file\n",
    "    print(\"Keys in the HDF5 file:\")\n",
    "    print(h5file.keys())\n",
    "\n",
    "    # Use visit method to print the entire structure of the file\n",
    "    print(\"\\nFile structure using visit:\")\n",
    "    h5file.visit(printPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7f564c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean value of dset_0: 0.32746875\n",
      "mean value of dset_1: 0.32349375\n",
      "\n",
      "################ file closed ################\n",
      "\n",
      "mean value of dset_0: 0.32746875\n",
      "could not read dset_1!\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(\"data/images.h5\", \"r\") as h5file:\n",
    "\n",
    "    # Read dset_0 into memory\n",
    "    dset_0 = h5file['image_data/dset_0'][:]\n",
    "\n",
    "    # read dset_1 as reference (is in the same group as dset_0)\n",
    "    dset_1 = h5file['image_data/dset_1']\n",
    "\n",
    "    print('mean value of dset_0:', np.mean(dset_0))\n",
    "    print('mean value of dset_1:', np.mean(dset_1))\n",
    "\n",
    "print('\\n################ file closed ################\\n')\n",
    "\n",
    "# Reference is not available any longer\n",
    "print('mean value of dset_0:', np.mean(dset_0))\n",
    "try:\n",
    "    print('mean value of dset_1:', np.mean(dset_1))\n",
    "except:\n",
    "    print('could not read dset_1!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0235e96b",
   "metadata": {},
   "source": [
    "## More advanced datasets with compound datatypes I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1c4871bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, [0.1, 0.2, 0.3], 25.5) (2, [1. , 2. , 3. ], 30. )]\n"
     ]
    }
   ],
   "source": [
    "# Define a compound datatype\n",
    "# The compound datatype consists of three fields: 'material', 'location', and 'temperature'\n",
    "# 'material' is an integer, 'location' is a 3-component float array, and 'temperature' is a float\n",
    "compound_datatype = np.dtype([\n",
    "    ('material', np.int32),\n",
    "    ('location', np.float64, (3,)),\n",
    "    ('temperature', np.float64)\n",
    "])\n",
    "\n",
    "# Sample data\n",
    "samples_data = np.array([\n",
    "    (1, [0.1, 0.2, 0.3], 25.5),\n",
    "    (2, [1.0, 2.0, 3.0], 30.0),\n",
    "], dtype=compound_datatype)\n",
    "\n",
    "# Create an HDF5 file and store the data\n",
    "with h5py.File('data/samples.h5', 'w') as h5file:\n",
    "    # Create a dataset with the compound datatype\n",
    "    samples_dataset = h5file.create_dataset('samples', data=samples_data)\n",
    "\n",
    "    # Retrieve data from the dataset\n",
    "    retrieved_data = samples_dataset[:]\n",
    "\n",
    "# Print the retrieved data\n",
    "print(retrieved_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea1e81b",
   "metadata": {},
   "source": [
    "## More advanced datasets with compound datatypes II"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "341965f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data from samples_1:\n",
      "[(5, [  0.5,  15.2,  70.5], 77.4) (1, [100.2,   5.4,   9. ], 64.2)]\n",
      "\n",
      "Data from samples_2:\n",
      "[(5, [  0.5,  15.2,  70.5], 77.4) (1, [100.2,   5.4,   9. ], 64.2)]\n",
      "\n",
      "Data from samples_3:\n",
      "[(5, [  0.5,  15.2,  70.5], 77.4) (1, [100.2,   5.4,   9. ], 64.2)]\n"
     ]
    }
   ],
   "source": [
    "# Define a compound datatype\n",
    "compound_datatype = np.dtype([\n",
    "    ('material', np.int32),\n",
    "    ('location', np.float64, (3,)),\n",
    "    ('temperature', np.float64)\n",
    "])\n",
    "\n",
    "# Provided samples\n",
    "materials = [5, 1]\n",
    "locations = [[0.5, 15.2, 70.5], [100.2, 5.4, 9.0]]\n",
    "temperatures = [77.4, 64.2]\n",
    "\n",
    "with h5py.File('data/more_complex_file.h5', 'a') as h5file:\n",
    "    # Write via slicing\n",
    "    group_1 = h5file.create_group('samples_1')\n",
    "    dset_1 = group_1.create_dataset('data', shape=(2,), dtype=compound_datatype)\n",
    "    dset_1[0] = (materials[0], locations[0], temperatures[0])\n",
    "    dset_1[1] = (materials[1], locations[1], temperatures[1])\n",
    "\n",
    "    # Write via field access\n",
    "    group_2 = h5file.create_group('samples_2')\n",
    "    dset_2 = group_2.create_dataset('data', shape=(2,), dtype=compound_datatype)\n",
    "    dset_2['material'] = materials\n",
    "    dset_2['location'] = locations\n",
    "    dset_2['temperature'] = temperatures\n",
    "\n",
    "    # Write via combination of both\n",
    "    group_3 = h5file.create_group('samples_3')\n",
    "    dset_3 = group_3.create_dataset('data', shape=(2,), dtype=compound_datatype)\n",
    "    h5file['samples_3']['data'][0] = (materials[0], locations[0], temperatures[0])\n",
    "    h5file['samples_3']['data'][1] = (materials[1], locations[1], temperatures[1])\n",
    "    \n",
    "    # Read and display data from group_1\n",
    "    print(\"Data from samples_1:\")\n",
    "    print(h5file['samples_1']['data'][:])\n",
    "\n",
    "    # Read and display data from group_2\n",
    "    print(\"\\nData from samples_2:\")\n",
    "    print(h5file['samples_2']['data'][:])\n",
    "\n",
    "    # Read and display data from group_3\n",
    "    print(\"\\nData from samples_3:\")\n",
    "    print(h5file['samples_3']['data'][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec413784",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
